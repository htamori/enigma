{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/htamori/enigma/blob/master/Untitled0.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "93iRVDOkzHty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "64da4873-b282-4ee1-8323-4668f703281c"
      },
      "cell_type": "code",
      "source": [
        "# google-drive-ocamlfuseのインストール\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Colab用のAuth token作成\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Drive FUSE library用のcredential生成\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# drive/ を作り、そこにGoogle Driveをマウントする\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpmlca1sqr/pubring.gpg' created\n",
            "gpg: /tmp/tmpmlca1sqr/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "··········\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kCqlbOfh2BXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wgF98IX3z8qK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "eda25a5e-187a-40ab-98a7-4679170e4a20"
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/kmaehashi/chainer-colab\n",
        "!pip install glob3\n",
        "!pip install sklearn\n",
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: glob3 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcusparse8.0 is already the newest version (8.0.61-1).\n",
            "libnvrtc8.0 is already the newest version (8.0.61-1).\n",
            "libnvtoolsext1 is already the newest version (8.0.61-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
            "Requirement already satisfied: cupy-cuda80 in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: chainer in /usr/local/lib/python3.6/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.14.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.11.0)\n",
            "Requirement already satisfied: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from chainer) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer) (39.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fSLDlM8RAFHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75f03109-4043-40b5-fb82-c1f428995d67"
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.5)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MdARiYa7vdVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "4450d775-a4b9-49a4-cd4e-4618b18f6c03"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "import copy\n",
        "import json\n",
        "\n",
        "total = ''\n",
        "chars = 'abcdefghijklmnopqrstuvwxyz., '\n",
        "char_index_0 = dict()\n",
        "char_index_1 = dict()\n",
        "\n",
        "random.seed(7104)\n",
        "tmp_random_0 = random.sample(range(0, 29), 29)\n",
        "random.seed(7105)\n",
        "tmp_random_1 = random.sample(range(0, 29), 29)\n",
        "\n",
        "\n",
        "for i in range(len(chars)):\n",
        "  char_index_0[chars[i]] = tmp_random_0[i]\n",
        "  char_index_1[chars[i]] = tmp_random_1[i]\n",
        "\n",
        "print(char_index_0)\n",
        "print(char_index_1)\n",
        "  \n",
        "for name in glob.glob('drive/Colab Notebooks/corpus/bbc/*/*'):\n",
        "  # print(name)\n",
        "  try:\n",
        "    text = open(name).read()\n",
        "  except Exception as ex:\n",
        "    continue\n",
        "  buff = []\n",
        "  for char in list(text.lower()):\n",
        "    if char in char_index_0:\n",
        "      buff.append(char)\n",
        "  total += ''.join(buff)\n",
        "\n",
        "# print(total)\n",
        "\n",
        "# random slice\n",
        "pairs = []\n",
        "for index in random.sample( list(range(0, len(total) - 150)),100000):\n",
        "  _char_index_0 = copy.copy(char_index_0)\n",
        "  _char_index_1 = copy.copy(char_index_1)\n",
        "  real = total[index:index+150]\n",
        "\n",
        "  enigma = []\n",
        "  for diff, char in enumerate(real):\n",
        "    # roater No.1 update _char_index\n",
        "    _char_index_0 = { char:(ind+1)%len(_char_index_0) for char, ind in _char_index_0.items() }\n",
        "    # get index\n",
        "    ind = _char_index_0[char]\n",
        "    next_char = chars[ind]\n",
        "\n",
        "    # roater No.2\n",
        "    _char_index_1 = { char:(ind+1)%len(_char_index_1) for char, ind in _char_index_1.items() }\n",
        "    # get index\n",
        "    ind = _char_index_1[next_char]\n",
        "    next_char = chars[ind]\n",
        "\n",
        "    enigma.append(next_char)\n",
        "  cript = ''.join(enigma)\n",
        "\n",
        "  crop = random.choice(list(range(len(char_index_0))))\n",
        "  real, cript = real[crop:crop+100], cript[crop:crop+100]\n",
        "  pairs.append( (real, cript) )\n",
        "\n",
        "open('drive/Colab Notebooks/corpus/pairs.json', 'w').write( json.dumps(pairs, indent=2) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 13, 'b': 23, 'c': 4, 'd': 10, 'e': 5, 'f': 15, 'g': 12, 'h': 7, 'i': 22, 'j': 1, 'k': 25, 'l': 27, 'm': 16, 'n': 11, 'o': 28, 'p': 20, 'q': 21, 'r': 19, 's': 6, 't': 14, 'u': 2, 'v': 8, 'w': 0, 'x': 3, 'y': 18, 'z': 24, '.': 9, ',': 17, ' ': 26}\n",
            "{'a': 16, 'b': 28, 'c': 19, 'd': 22, 'e': 24, 'f': 14, 'g': 21, 'h': 4, 'i': 8, 'j': 23, 'k': 5, 'l': 26, 'm': 2, 'n': 9, 'o': 17, 'p': 0, 'q': 1, 'r': 10, 's': 3, 't': 20, 'u': 11, 'v': 6, 'w': 13, 'x': 25, 'y': 12, 'z': 7, '.': 15, ',': 27, ' ': 18}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22400002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "l4BV73Brrcxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "\n",
        "from chainer import Chain\n",
        "from chainer import cuda\n",
        "from chainer import optimizers\n",
        "from chainer import serializers\n",
        "from chainer import Variable\n",
        "\n",
        "import configparser\n",
        "import cupy\n",
        "\n",
        "class decrypt_enigma(chainer.Chain):\n",
        "  def __init__(self, encode_vocab_size, decode_vocab_size, dim_embed, n_bilstm_layer, n_lstm_layer, n_hidden_layer, n_lstm_dropout):\n",
        "    super(decrypt_enigma, self).__init__(\n",
        "      enc_embed = L.EmbedID(encode_vocab_size, dim_embed),\n",
        "      enc_lstm = L.NStepBiLSTM(n_bilstm_layer, dim_embed, n_hidden_layer, n_lstm_dropout),\n",
        "\n",
        "      dec_embed = L.EmbedID(decode_vocab_size, dim_embed),\n",
        "        \n",
        "      enc_to_dec_hidden = L.Linear(n_hidden_layer * 2, n_hidden_layer),\n",
        "      enc_to_dec_cell = L.Linear(n_hidden_layer * 2, n_hidden_layer),\n",
        "                \n",
        "      dec_lstm = L.NStepLSTM(n_lstm_layer, dim_embed, n_hidden_layer, n_lstm_dropout),\n",
        "      dec_linear = L.Linear(n_hidden_layer, decode_vocab_size),\n",
        "    )\n",
        "    \n",
        "  def __call__(self, encrypted, original_in, original_out):\n",
        "    batch_size = len(encrypted)\n",
        "    embedding_encrypted = [self.enc_embed(sent_encrypted) for sent_encrypted in encrypted]\n",
        "    embedding_original_in = [self.dec_embed(sent_original) for sent_original in original_in]\n",
        "\n",
        "    hidden_states, cell_states, _ = self.enc_lstm(None, None, embedding_encrypted)\n",
        "    hidden_states = F.concat(hidden_states, axis=1)\n",
        "    #hidden_states = F.reshape(hidden_states, (1, hidden_states.shape[0], hidden_states.shape[1]))\n",
        "    cell_states = F.concat(cell_states, axis=1)\n",
        "    #cell_states = F.reshape(cell_states, (1, cell_states.shape[0], cell_states.shape[1]))\n",
        "    \n",
        "    hidden = self.enc_to_dec_hidden(hidden_states)\n",
        "    cell = self.enc_to_dec_cell(cell_states)\n",
        "    # print(hidden.shape, cell.shape)\n",
        "    hidden = F.reshape(hidden, (1, hidden.shape[0], hidden.shape[1]))\n",
        "    cell = F.reshape(cell, (1, cell.shape[0], cell.shape[1]))\n",
        "    \n",
        "    _, _, embedded_outputs = self.dec_lstm(hidden, cell, embedding_original_in)\n",
        "   \n",
        "    loss = 0.0\n",
        "    for embedded_output, original in zip(embedded_outputs, original_out):\n",
        "      # print(embedded_output.shape)\n",
        "      output = self.dec_linear(embedded_output)\n",
        "      loss += F.softmax_cross_entropy(output, original)\n",
        "\n",
        "    \n",
        "    loss /= batch_size\n",
        "    return loss\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3uUxRizv6Jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1416
        },
        "outputId": "c12bf788-3875-4215-c16a-2409ce1c33c3"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "with open('drive/Colab Notebooks/corpus/pairs.json', 'r') as f:\n",
        "  json_cont = json.loads(f.read())\n",
        "\n",
        "original = []\n",
        "encrypted = []\n",
        "eos = '<eos>'\n",
        "for pair in json_cont:\n",
        "  tmp_original_in = list(pair[0])\n",
        "  tmp_original_out = list(pair[0])\n",
        "  tmp_encrypted = list(pair[1])\n",
        "\n",
        "  tmp_original_in.insert(0, eos)\n",
        "  tmp_original_out.append(eos)\n",
        "  tmp_encrypted.append(eos)\n",
        "  tmp_original=[tmp_original_in, tmp_original_out]      \n",
        "  original.append(tmp_original)\n",
        "\n",
        "  encrypted.append(tmp_encrypted)\n",
        "\n",
        "print('total size of original data: {}, encrypted: {}'.format(str(len(original)), str(len(encrypted))))\n",
        "print(original[0])\n",
        "char_to_id = {}\n",
        "id_to_char = {}\n",
        "chars = 'abcdefghijklmnopqrstuvwxyz., '\n",
        "for i in range(len(chars)):\n",
        "  char_to_id[chars[i]] = i\n",
        "  id_to_char[i] = chars[i]\n",
        "  \n",
        "char_to_id[eos] = len(chars)\n",
        "id_to_char[len(chars)] = eos\n",
        "\n",
        "ided_original = []\n",
        "ided_encrypted = []\n",
        "for orig_sent in original:\n",
        "  temp_in = []\n",
        "  temp_out = []\n",
        "  for orig_char in orig_sent[0]:\n",
        "    temp_in.append(char_to_id[orig_char])\n",
        "  for orig_char in orig_sent[1]:\n",
        "    temp_out.append(char_to_id[orig_char])\n",
        "  temp = [temp_in, temp_out]\n",
        "  ided_original.append(temp)\n",
        "  \n",
        "for enc_sent in encrypted:\n",
        "  temp = []\n",
        "  for enc_char in enc_sent:\n",
        "    temp.append(char_to_id[enc_char])\n",
        "  ided_encrypted.append(temp)\n",
        "\n",
        "  \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_original, t_original, x_encrypted, t_encrypted = train_test_split(ided_original, \n",
        "                                                                    ided_encrypted,\n",
        "                                                                    test_size=0.05)\n",
        "\n",
        "print('size of training data: {}, test_data: {}'.format(str(len(x_original)), str(len(t_original))))\n",
        "print(x_original[0])\n",
        "print(x_encrypted[0])\n",
        "N = len(x_original)\n",
        "N_test = len(t_original)\n",
        "\n",
        "model = decrypt_enigma(30, 30, 128, 1, 1, 512, 0.1)\n",
        "optimizer = optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer.GradientClipping(5))\n",
        "\n",
        "batch_train = 128\n",
        "batch_test = 1\n",
        "n_epoch = 10\n",
        "\n",
        "cuda.check_cuda_available()\n",
        "cuda.get_device(0).use()\n",
        "xp = cupy\n",
        "if xp == cupy:\n",
        "  model.to_gpu()\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  perm = np.random.permutation(N)\n",
        "  for i in range(0, N, batch_train):\n",
        "    model.cleargrads()\n",
        "    index = perm[i: (i+batch_train) if (i+batch_train) < N else N]\n",
        "    batch_encrypted = [Variable(xp.array(x_encrypted[j], dtype=xp.int32)) for j in index]\n",
        "    batch_original_in = [Variable(xp.array(x_original[j][0], dtype=xp.int32)) for j in index]\n",
        "    batch_original_out = [Variable(xp.array(x_original[j][1], dtype=xp.int32)) for j in index]\n",
        "\n",
        "    loss = model(batch_encrypted, batch_original_in, batch_original_out)\n",
        "    print(loss.data)\n",
        "    loss.backward()\n",
        "    optimizer.update()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total size of original data: 100000, encrypted: 100000\n",
            "[['<eos>', 'a', 't', 't', 'a', 'c', 'k', '.', 't', 'o', 'r', 'y', ' ', 'l', 'e', 'a', 'd', 'e', 'r', ' ', 'm', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'h', 'o', 'w', 'a', 'r', 'd', ' ', 'h', 'a', 's', ' ', 'a', 'c', 'c', 'u', 's', 'e', 'd', ' ', 'm', 'r', ' ', 'b', 'l', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 's', 't', 'e', 'a', 'm', 'r', 'o', 'l', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'p', 'l', 'a', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'o', 'f'], ['a', 't', 't', 'a', 'c', 'k', '.', 't', 'o', 'r', 'y', ' ', 'l', 'e', 'a', 'd', 'e', 'r', ' ', 'm', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'h', 'o', 'w', 'a', 'r', 'd', ' ', 'h', 'a', 's', ' ', 'a', 'c', 'c', 'u', 's', 'e', 'd', ' ', 'm', 'r', ' ', 'b', 'l', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 's', 't', 'e', 'a', 'm', 'r', 'o', 'l', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'p', 'l', 'a', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'o', 'f', '<eos>']]\n",
            "size of training data: 95000, test_data: 5000\n",
            "[[29, 28, 11, 14, 17, 3, 18, 26, 28, 8, 28, 22, 0, 13, 19, 28, 18, 14, 12, 4, 1, 14, 3, 24, 28, 19, 7, 4, 17, 4, 28, 22, 7, 14, 28, 8, 18, 28, 6, 14, 8, 13, 6, 28, 19, 14, 28, 11, 14, 14, 10, 28, 0, 5, 19, 4, 17, 28, 19, 7, 0, 19, 28, 7, 14, 20, 18, 4, 28, 0, 13, 3, 28, 3, 14, 28, 0, 28, 9, 14, 1, 28, 19, 7, 4, 17, 4, 26, 12, 15, 18, 28, 16, 20, 8, 25, 28, 0, 8, 3, 4], [28, 11, 14, 17, 3, 18, 26, 28, 8, 28, 22, 0, 13, 19, 28, 18, 14, 12, 4, 1, 14, 3, 24, 28, 19, 7, 4, 17, 4, 28, 22, 7, 14, 28, 8, 18, 28, 6, 14, 8, 13, 6, 28, 19, 14, 28, 11, 14, 14, 10, 28, 0, 5, 19, 4, 17, 28, 19, 7, 0, 19, 28, 7, 14, 20, 18, 4, 28, 0, 13, 3, 28, 3, 14, 28, 0, 28, 9, 14, 1, 28, 19, 7, 4, 17, 4, 26, 12, 15, 18, 28, 16, 20, 8, 25, 28, 0, 8, 3, 4, 29]]\n",
            "[22, 5, 26, 20, 27, 10, 5, 3, 3, 28, 11, 14, 20, 22, 19, 15, 15, 13, 26, 21, 18, 7, 27, 1, 13, 9, 12, 12, 24, 22, 25, 20, 18, 28, 14, 26, 3, 15, 20, 23, 28, 15, 14, 18, 9, 18, 16, 3, 16, 26, 18, 12, 12, 13, 20, 3, 1, 1, 21, 24, 8, 15, 9, 1, 17, 9, 10, 28, 18, 28, 0, 14, 17, 9, 18, 12, 17, 26, 18, 20, 20, 5, 10, 20, 3, 11, 10, 6, 1, 13, 15, 14, 26, 10, 22, 24, 26, 23, 11, 26, 29]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "CUDARuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCUDARuntimeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-474825442609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/link.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/link.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/variable.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/variable.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Renew placeholder to break sharing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/backends/cuda.py\u001b[0m in \u001b[0;36mto_gpu\u001b[0;34m(array, device, stream)\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_array_to_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/backends/cuda.py\u001b[0m in \u001b[0;36m_array_to_gpu\u001b[0;34m(array, device, stream)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marray_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# Need to make a copy when an array is copied to another device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/cupy/creation/from_data.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \"\"\"\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.array\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPointer.copy_from_host_async\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/runtime.pyx\u001b[0m in \u001b[0;36mcupy.cuda.runtime.memcpyAsync\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/cuda/runtime.pyx\u001b[0m in \u001b[0;36mcupy.cuda.runtime.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCUDARuntimeError\u001b[0m: cudaErrorIllegalAddress: an illegal memory access was encountered"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "M0IecsTTwL0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "94912518-0f27-4bc6-e6a4-0fff10d2a8d4"
      },
      "cell_type": "code",
      "source": [
        "json_cont"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-278e3759c8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_cont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'json_cont' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ES1vN_tUwMF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "FVQyfWV2zCo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "1db7e6b5-6556-4791-8300-9f60e8015eb2"
      },
      "cell_type": "code",
      "source": [
        "a = [[[1,2,3],[4,5,6]],[[3,2,1],[6,5,4]]]\n",
        "v_a = Variable(np.array(a, dtype=np.int32))\n",
        "print(v_a.shape)\n",
        "v_c = F.concat([v_a[0], v_a[1]], axis=1)\n",
        "v_c = F.reshape(v_c, (1, v_c.shape[0],  v_c.shape[1]))\n",
        "print(v_c)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3fa4c8a20464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mv_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mv_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RrjAxeZR_5vM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "4bb8d10c-0fb2-4e1d-96e9-19faeec56ed5"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug  9 10:29:38 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   34C    P0    53W / 149W |   2248MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o9cveclcJJkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "480c1f03-fc22-4c42-99b7-d15b225119f5"
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root        77  0.0  0.4 185472 60308 ?        Sl   06:34   0:08 /usr/bin/python2 /usr/local/bin/jupyter-notebook -y --no-browser --log-level=DEBUG --debug --NotebookApp.allow_origin=\"*\" --NotebookApp.log_format=\"%(message)s\" --NotebookApp.disable_check_xsrf=True --NotebookApp.token= --Session.key=\"\" --Session.keyfile=\"\" --ContentsManager.untitled_directory=\"Untitled Folder\" --ContentsManager.untitled_file=\"Untitled File\" --ContentsManager.untitled_notebook=\"Untitled Notebook\" --KernelManager.autorestart=True --MultiKernelManager.default_kernel_name=\"python2\" --ip=\"172.28.0.2\" --port=9000 --port-retries=0 --notebook-dir=\"/content\" --NotebookApp.base_url=/tun/m/gpu-bgnwrsit2fuk/\r\n",
            "root        85  2.0 13.8 40983856 1850672 ?    Ssl  06:35   4:17 /usr/bin/python3 -m ipykernel_launcher -f /content/.local/share/jupyter/runtime/kernel-0c800f45-46e8-4ae5-a5d9-d19ee9b79f9b.json\r\n",
            "root      4577 98.0  0.0  33960  4916 pts/0    Ss+  10:05   0:00 /bin/sh -c ps aux | grep python\r\n",
            "root      4579  0.0  0.0  38200  5792 pts/0    S+   10:05   0:00 grep python\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IuBnT3FtJPej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}