{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/htamori/enigma/blob/master/Untitled0.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "93iRVDOkzHty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2503
        },
        "outputId": "4d1a88a7-0778-49a9-e18f-e0356fbb9964"
      },
      "cell_type": "code",
      "source": [
        "# google-drive-ocamlfuseのインストール\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Colab用のAuth token作成\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Drive FUSE library用のcredential生成\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# drive/ を作り、そこにGoogle Driveをマウントする\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../04-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../05-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../06-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../07-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../08-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../09-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../10-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../11-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../12-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../13-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../14-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../15-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../16-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../17-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../18-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../19-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../20-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../21-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../22-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../23-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n",
            "Setting up lsb-release (9.20160110ubuntu5) ...\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmpkjddtufm/pubring.gpg' created\n",
            "gpg: /tmp/tmpkjddtufm/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19816 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kCqlbOfh2BXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e543ef79-b30c-4625-e30d-d3ee984fc9a5"
      },
      "cell_type": "code",
      "source": [
        "!ls drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'drive': No such file or directory\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wgF98IX3z8qK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1315
        },
        "outputId": "b011b838-7f52-40e2-d291-8509d5f6334a"
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/kmaehashi/chainer-colab\n",
        "!pip install glob3\n",
        "!pip install sklearn\n",
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer\n",
        "!pip install tqdm\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glob3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/21/e042ea7bcb917bac5cf2365d532d44efc23650be81456546a6e89e25371e/glob3-0.0.1.tar.gz\n",
            "Building wheels for collected packages: glob3\n",
            "  Running setup.py bdist_wheel for glob3 ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5c/db/36/aae4683ac0ba95eb154510b48d6bda87fbaac71b6a9b62123d\n",
            "Successfully built glob3\n",
            "Installing collected packages: glob3\n",
            "Successfully installed glob3-0.0.1\n",
            "Collecting sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.2)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
            "0 upgraded, 3 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 28.9 MB of archives.\n",
            "After this operation, 71.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libcusparse8.0 amd64 8.0.61-1 [22.6 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libnvrtc8.0 amd64 8.0.61-1 [6,225 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful/multiverse amd64 libnvtoolsext1 amd64 8.0.61-1 [32.2 kB]\n",
            "Fetched 28.9 MB in 2s (14.5 MB/s)\n",
            "\n",
            "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libcusparse8.0:amd64.\n",
            "(Reading database ... 19845 files and directories currently installed.)\n",
            "Preparing to unpack .../libcusparse8.0_8.0.61-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libcusparse8.0:amd64 (8.0.61-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libnvrtc8.0:amd64.\n",
            "Preparing to unpack .../libnvrtc8.0_8.0.61-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking libnvrtc8.0:amd64 (8.0.61-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libnvtoolsext1:amd64.\n",
            "Preparing to unpack .../libnvtoolsext1_8.0.61-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 43%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libnvtoolsext1:amd64 (8.0.61-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up libnvtoolsext1:amd64 (8.0.61-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 62%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libcusparse8.0:amd64 (8.0.61-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 81%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Setting up libnvrtc8.0:amd64 (8.0.61-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "\n",
            "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JCollecting cupy-cuda80\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/7e/b7fd9dbcf4940789a08f8c2fc8a55a2cd0d1bfd08e843ed261c697c092f8/cupy_cuda80-4.4.0-cp36-cp36m-manylinux1_x86_64.whl (200.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 200.6MB 183kB/s \n",
            "\u001b[?25hCollecting chainer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/8e/6ea17aacbbd0963e7f7e8ae68de6e87ba2449d3ec263e1a407c8ebaf980b/chainer-4.4.0.tar.gz (401kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.11.0)\n",
            "Collecting fastrlock>=0.3 (from cupy-cuda80)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/24/767ce4fe23af5a4b3dd229c0e3153a26c0a58331f8f89af324c761663c9c/fastrlock-0.3-cp36-cp36m-manylinux1_x86_64.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda80) (1.14.5)\n",
            "Collecting filelock (from chainer)\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/8c/8d6162a00b0f47c6b8bb089fc0e0f8ffda0331cd6ab2d8ac00158c6ce87d/filelock-3.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from chainer) (3.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.0.0->chainer) (39.1.0)\n",
            "Building wheels for collected packages: chainer\n",
            "  Running setup.py bdist_wheel for chainer ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/75/3c/11/c621c36f71bb24fd19bd9e023c9dee73c9adc8e2948aa8c96e\n",
            "Successfully built chainer\n",
            "Installing collected packages: fastrlock, cupy-cuda80, filelock, chainer\n",
            "Successfully installed chainer-4.4.0 cupy-cuda80-4.4.0 fastrlock-0.3 filelock-3.0.6\n",
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/e0/52b2faaef4fd87f86eb8a8f1afa2cd6eb11146822033e29c04ac48ada32c/tqdm-4.25.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.25.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MdARiYa7vdVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "4450d775-a4b9-49a4-cd4e-4618b18f6c03"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import random\n",
        "import copy\n",
        "import json\n",
        "\n",
        "total = ''\n",
        "chars = 'abcdefghijklmnopqrstuvwxyz., '\n",
        "char_index_0 = dict()\n",
        "char_index_1 = dict()\n",
        "\n",
        "random.seed(7104)\n",
        "tmp_random_0 = random.sample(range(0, 29), 29)\n",
        "random.seed(7105)\n",
        "tmp_random_1 = random.sample(range(0, 29), 29)\n",
        "\n",
        "\n",
        "for i in range(len(chars)):\n",
        "  char_index_0[chars[i]] = tmp_random_0[i]\n",
        "  char_index_1[chars[i]] = tmp_random_1[i]\n",
        "\n",
        "print(char_index_0)\n",
        "print(char_index_1)\n",
        "  \n",
        "for name in glob.glob('drive/Colab Notebooks/corpus/bbc/*/*'):\n",
        "  # print(name)\n",
        "  try:\n",
        "    text = open(name).read()\n",
        "  except Exception as ex:\n",
        "    continue\n",
        "  buff = []\n",
        "  for char in list(text.lower()):\n",
        "    if char in char_index_0:\n",
        "      buff.append(char)\n",
        "  total += ''.join(buff)\n",
        "\n",
        "# print(total)\n",
        "\n",
        "# random slice\n",
        "pairs = []\n",
        "for index in random.sample( list(range(0, len(total) - 150)),100000):\n",
        "  _char_index_0 = copy.copy(char_index_0)\n",
        "  _char_index_1 = copy.copy(char_index_1)\n",
        "  real = total[index:index+150]\n",
        "\n",
        "  enigma = []\n",
        "  for diff, char in enumerate(real):\n",
        "    # roater No.1 update _char_index\n",
        "    _char_index_0 = { char:(ind+1)%len(_char_index_0) for char, ind in _char_index_0.items() }\n",
        "    # get index\n",
        "    ind = _char_index_0[char]\n",
        "    next_char = chars[ind]\n",
        "\n",
        "    # roater No.2\n",
        "    _char_index_1 = { char:(ind+1)%len(_char_index_1) for char, ind in _char_index_1.items() }\n",
        "    # get index\n",
        "    ind = _char_index_1[next_char]\n",
        "    next_char = chars[ind]\n",
        "\n",
        "    enigma.append(next_char)\n",
        "  cript = ''.join(enigma)\n",
        "\n",
        "  crop = random.choice(list(range(len(char_index_0))))\n",
        "  real, cript = real[crop:crop+100], cript[crop:crop+100]\n",
        "  pairs.append( (real, cript) )\n",
        "\n",
        "open('drive/Colab Notebooks/corpus/pairs.json', 'w').write( json.dumps(pairs, indent=2) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 13, 'b': 23, 'c': 4, 'd': 10, 'e': 5, 'f': 15, 'g': 12, 'h': 7, 'i': 22, 'j': 1, 'k': 25, 'l': 27, 'm': 16, 'n': 11, 'o': 28, 'p': 20, 'q': 21, 'r': 19, 's': 6, 't': 14, 'u': 2, 'v': 8, 'w': 0, 'x': 3, 'y': 18, 'z': 24, '.': 9, ',': 17, ' ': 26}\n",
            "{'a': 16, 'b': 28, 'c': 19, 'd': 22, 'e': 24, 'f': 14, 'g': 21, 'h': 4, 'i': 8, 'j': 23, 'k': 5, 'l': 26, 'm': 2, 'n': 9, 'o': 17, 'p': 0, 'q': 1, 'r': 10, 's': 3, 't': 20, 'u': 11, 'v': 6, 'w': 13, 'x': 25, 'y': 12, 'z': 7, '.': 15, ',': 27, ' ': 18}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22400002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "UaCMBYrxiQEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "l4BV73Brrcxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "\n",
        "from chainer import Chain\n",
        "from chainer import cuda\n",
        "from chainer import optimizers\n",
        "from chainer import serializers\n",
        "from chainer import Variable\n",
        "\n",
        "import configparser\n",
        "import cupy\n",
        "import numpy as np\n",
        "\n",
        "class decrypt_enigma(chainer.Chain):\n",
        "  def __init__(self, encode_vocab_size, decode_vocab_size, dim_embed, n_bilstm_layer, n_lstm_layer, n_hidden_layer, n_lstm_dropout):\n",
        "    self.vocab_size = decode_vocab_size\n",
        "    super(decrypt_enigma, self).__init__(\n",
        "      enc_embed = L.EmbedID(encode_vocab_size, dim_embed),\n",
        "      enc_lstm = L.NStepBiLSTM(n_lstm_layer, dim_embed, n_hidden_layer, n_lstm_dropout),\n",
        "\n",
        "      dec_embed = L.EmbedID(decode_vocab_size, dim_embed),\n",
        "                        \n",
        "      dec_lstm = L.NStepLSTM(n_lstm_layer, dim_embed, n_hidden_layer * 2, n_lstm_dropout),\n",
        "      attention = L.Linear(n_hidden_layer * 4, n_hidden_layer * 2),\n",
        "      dec_linear = L.Linear(n_hidden_layer * 2, decode_vocab_size),\n",
        "    )\n",
        "    \n",
        "  def reset_state(self):\n",
        "    self.enc_lstm.reset_state()\n",
        "    self.dec_lstm.reset_state()\n",
        "    \n",
        "  def __call__(self, encrypted, original_in, original_out):\n",
        "    \n",
        "    batch_size = len(encrypted)\n",
        "    embedding_encrypted = [self.enc_embed(sent_encrypted) for sent_encrypted in encrypted]\n",
        "    embedding_original_in = [self.dec_embed(sent_original) for sent_original in original_in]\n",
        "\n",
        "    hidden_states, cell_states, time_step_hidden_states = self.enc_lstm(None, None, embedding_encrypted)\n",
        "    hidden_states = F.concat(hidden_states, axis=1)\n",
        "    hidden_states = F.reshape(hidden_states, (1, hidden_states.shape[0], hidden_states.shape[1]))\n",
        "    cell_states = F.concat(cell_states, axis=1)\n",
        "    cell_states = F.reshape(cell_states, (1, cell_states.shape[0], cell_states.shape[1]))\n",
        "    \n",
        "#     hidden = F.relu(self.enc_to_dec_hidden(hidden_states))\n",
        "#     cell = F.relu(self.enc_to_dec_cell(cell_states))\n",
        "    # print(hidden.shape, cell.shape)\n",
        "#     hidden = F.reshape(hidden, (1, hidden.shape[0], hidden.shape[1]))\n",
        "#     cell = F.reshape(cell, (1, cell.shape[0], cell.shape[1]))\n",
        "    # print(hidden_states.shape, cell_states.shape)\n",
        "\n",
        "    \n",
        "    _, _, embedded_outputs = self.dec_lstm(hidden_states, cell_states, embedding_original_in)\n",
        "    # print(embedded_outputs.shape)\n",
        "    loss = 0.0\n",
        "    for embedded_output, original, time_step_hidden_state in zip(embedded_outputs, original_out, time_step_hidden_states):\n",
        "      # print(embedded_output.shape)\n",
        "      output = self._calculate_attention_layer_output(embedded_output, time_step_hidden_state)\n",
        "      loss += F.softmax_cross_entropy(output, original)\n",
        "\n",
        "    \n",
        "    loss /= batch_size\n",
        "    return loss\n",
        "  \n",
        "  def _calculate_attention_layer_output(self, embedded_output, attention):\n",
        "      inner_prod = F.matmul(embedded_output, attention, transb=True)\n",
        "      weights = F.softmax(inner_prod)\n",
        "      contexts = F.matmul(weights, attention)\n",
        "      concatenated = F.concat((contexts, embedded_output))\n",
        "      new_embedded_output = F.tanh(self.attention(concatenated))\n",
        "      return self.dec_linear(new_embedded_output)  \n",
        "    \n",
        "  def translate(self, encrypted, original, eos_id=29, max_len=101):\n",
        "    with chainer.no_backprop_mode(), chainer.using_config('train', False):\n",
        "      \n",
        "      embedding_encrypted = [self.enc_embed(sent_encrypted) for sent_encrypted in encrypted]\n",
        "      \n",
        "      hidden_states, cell_states, time_step_hidden_states = self.enc_lstm(None, None, embedding_encrypted)\n",
        "      hidden_states = F.concat(hidden_states, axis=1)\n",
        "      cell_states = F.concat(cell_states, axis=1)\n",
        "#       hidden = F.relu(self.enc_to_dec_hidden(hidden_states))\n",
        "#       cell = F.relu(self.enc_to_dec_cell(cell_states))\n",
        "#       # print(hidden.shape, cell.shape)\n",
        "      hidden_states = F.reshape(hidden_states, (1, hidden_states.shape[0], hidden_states.shape[1]))\n",
        "      cell_states = F.reshape(cell_states, (1, cell_states.shape[0], cell_states.shape[1]))\n",
        "\n",
        "      wid = eos_id\n",
        "      output_for_sce = [] # p.zeros((0, self.vocab_size))\n",
        "      ret_id_seq = []\n",
        "      for i in range(max_len):\n",
        "        wid_xparray = Variable(self.xp.array([wid], dtype=self.xp.int32))\n",
        "        wid_embedding = self.dec_embed(wid_xparray)\n",
        "        hidden_states, cell_states, output = self.dec_lstm(hidden_states, cell_states, [wid_embedding])\n",
        "        output = self._calculate_attention_layer_output(output[0], time_step_hidden_states[0])\n",
        "        # print(output[0])\n",
        "        output_for_sce.append(output[0].data)\n",
        "        output_softmax = F.softmax(output)\n",
        "        wid = np.argmax(output_softmax.data)\n",
        "        ret_id_seq.append(wid.tolist())\n",
        "        if wid == eos_id:\n",
        "          break\n",
        "      # print(output_for_sce)\n",
        "      \n",
        "      ignoring_array = self.xp.array([-1 for i in range(self.vocab_size)], dtype=self.xp.float32)\n",
        "      while len(output_for_sce) != original.shape[0]:\n",
        "        output_for_sce.append(ignoring_array)\n",
        "      # print(output_for_sce)\n",
        "\n",
        "      v_output_for_sce = Variable(self.xp.array(output_for_sce, dtype=self.xp.float32))\n",
        "      loss = F.softmax_cross_entropy(v_output_for_sce, original)\n",
        "      # print(ret_id_seq)\n",
        "      return ret_id_seq, loss\n",
        " \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3uUxRizv6Jp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2161
        },
        "outputId": "48d20c32-924f-4011-e346-857cb388510c"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "with open('drive/Colab Notebooks/corpus/pairs.json', 'r') as f:\n",
        "  json_cont = json.loads(f.read())\n",
        "\n",
        "original = []\n",
        "encrypted = []\n",
        "eos = '<eos>'\n",
        "for pair in json_cont:\n",
        "  tmp_original_in = list(pair[0])\n",
        "  tmp_original_out = list(pair[0])\n",
        "  tmp_encrypted = list(pair[1])\n",
        "\n",
        "  tmp_original_in.insert(0, eos)\n",
        "  tmp_original_out.append(eos)\n",
        "  tmp_encrypted.append(eos)\n",
        "  tmp_original=[tmp_original_in, tmp_original_out]      \n",
        "  original.append(tmp_original)\n",
        "\n",
        "  encrypted.append(tmp_encrypted)\n",
        "\n",
        "print('total size of original data: {}, encrypted: {}'.format(str(len(original)), str(len(encrypted))))\n",
        "print(original[0])\n",
        "char_to_id = {}\n",
        "id_to_char = {}\n",
        "chars = 'abcdefghijklmnopqrstuvwxyz., '\n",
        "for i in range(len(chars)):\n",
        "  char_to_id[chars[i]] = i\n",
        "  id_to_char[i] = chars[i]\n",
        "  \n",
        "char_to_id[eos] = len(chars)\n",
        "id_to_char[len(chars)] = eos\n",
        "\n",
        "ided_original = []\n",
        "ided_encrypted = []\n",
        "for orig_sent in original:\n",
        "  temp_in = []\n",
        "  temp_out = []\n",
        "  for orig_char in orig_sent[0]:\n",
        "    temp_in.append(char_to_id[orig_char])\n",
        "  for orig_char in orig_sent[1]:\n",
        "    temp_out.append(char_to_id[orig_char])\n",
        "  temp = [temp_in, temp_out]\n",
        "  ided_original.append(temp)\n",
        "  \n",
        "for enc_sent in encrypted:\n",
        "  temp = []\n",
        "  for enc_char in enc_sent:\n",
        "    temp.append(char_to_id[enc_char])\n",
        "  ided_encrypted.append(temp)\n",
        "\n",
        "  \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_original, t_original, x_encrypted, t_encrypted = train_test_split(ided_original, \n",
        "                                                                    ided_encrypted,\n",
        "                                                                    test_size=0.005)\n",
        "\n",
        "print('size of training data: {}, test_data: {}'.format(str(len(x_original)), str(len(t_original))))\n",
        "print(t_original[-1])\n",
        "print(t_encrypted[-1])\n",
        "N = len(x_original)\n",
        "N_test = len(t_original)\n",
        "\n",
        "model = decrypt_enigma(30, 30, 256, 1, 1, 512, 0.25)\n",
        "optimizer = optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer.GradientClipping(5))\n",
        "\n",
        "batch_train = 128\n",
        "batch_test = 1\n",
        "n_epoch = 10\n",
        "\n",
        "cuda.check_cuda_available()\n",
        "cuda.get_device(0).use()\n",
        "xp = cupy\n",
        "if xp == cupy:\n",
        "  model.to_gpu()\n",
        "\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # model.reset_state()\n",
        "  perm = np.random.permutation(N)\n",
        "  # bar = tqdm(total=int(N/batch_train))\n",
        "  acc_loss = 0.0\n",
        "  for i in range(0, N, batch_train):\n",
        "    model.cleargrads()\n",
        "    index = perm[i: (i+batch_train) if (i+batch_train) < N else N]\n",
        "    batch_encrypted = [Variable(xp.array(x_encrypted[j], dtype=xp.int32)) for j in index]\n",
        "    batch_original_in = [Variable(xp.array(x_original[j][0], dtype=xp.int32)) for j in index]\n",
        "    batch_original_out = [Variable(xp.array(x_original[j][1], dtype=xp.int32)) for j in index]\n",
        "\n",
        "    loss = model(batch_encrypted, batch_original_in, batch_original_out)\n",
        "    acc_loss += loss.data\n",
        "    loss.backward()\n",
        "    optimizer.update()\n",
        "    if i % 100 == 0:\n",
        "      print('epoch {}/ batch {} trained'.format(str(epoch), str(i)))\n",
        "  acc_loss /= int(N/batch_train)\n",
        "  \n",
        "  acc_test_loss = 0.0\n",
        "  for i in range(0, N_test):\n",
        "    test_encrypted = [Variable(xp.array(t_encrypted[i], dtype=xp.int32))]\n",
        "    test_original = Variable(xp.array(t_original[i][1], dtype=xp.int32))\n",
        "    translate_id_seq, loss = model.translate(test_encrypted, test_original)\n",
        "    # print(translate_id_seq)\n",
        "    acc_test_loss += loss.data\n",
        "  acc_test_loss /= N_test\n",
        "    \n",
        "  print('epoch:{}, train_loss:{}, test_loss:{}'.format(str(epoch), str(acc_loss), str(acc_test_loss)))\n",
        "  #print(translate_id_seq)\n",
        "  id_to_char_encrypted = [id_to_char[t_encrypted[-1][j]] for j in range(len(t_encrypted[-1]))]\n",
        "  id_to_char_decoded = [id_to_char[translate_id_seq[j]] for j in range(len(translate_id_seq))]\n",
        "  id_to_char_original = [id_to_char[t_original[-1][1][j]] for j in range(len(t_original[-1][1]))]\n",
        "  print('encrypted: {}'.format(''.join(id_to_char_encrypted)))\n",
        "  print('decoded: {}'.format(''.join(id_to_char_decoded)))\n",
        "  print('original: {}'.format(''.join(id_to_char_original)))\n",
        "\n",
        "  outfile = 'drive/Colab Notebooks/model_epoch{}_{}.npz'.format(str(epoch), str(acc_test_loss))\n",
        "  serializers.save_npz(outfile, model)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total size of original data: 100000, encrypted: 100000\n",
            "[['<eos>', 'a', 't', 't', 'a', 'c', 'k', '.', 't', 'o', 'r', 'y', ' ', 'l', 'e', 'a', 'd', 'e', 'r', ' ', 'm', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'h', 'o', 'w', 'a', 'r', 'd', ' ', 'h', 'a', 's', ' ', 'a', 'c', 'c', 'u', 's', 'e', 'd', ' ', 'm', 'r', ' ', 'b', 'l', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 's', 't', 'e', 'a', 'm', 'r', 'o', 'l', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'p', 'l', 'a', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'o', 'f'], ['a', 't', 't', 'a', 'c', 'k', '.', 't', 'o', 'r', 'y', ' ', 'l', 'e', 'a', 'd', 'e', 'r', ' ', 'm', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'h', 'o', 'w', 'a', 'r', 'd', ' ', 'h', 'a', 's', ' ', 'a', 'c', 'c', 'u', 's', 'e', 'd', ' ', 'm', 'r', ' ', 'b', 'l', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 's', 't', 'e', 'a', 'm', 'r', 'o', 'l', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'p', 'l', 'a', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'o', 'f', '<eos>']]\n",
            "size of training data: 99500, test_data: 500\n",
            "[[29, 28, 19, 14, 28, 4, 12, 15, 11, 14, 24, 4, 4, 18, 28, 15, 17, 8, 21, 0, 2, 24, 28, 1, 20, 19, 28, 0, 11, 18, 14, 28, 19, 14, 28, 19, 7, 4, 28, 17, 4, 11, 0, 19, 8, 14, 13, 18, 7, 8, 15, 28, 1, 4, 19, 22, 4, 4, 13, 28, 4, 12, 15, 11, 14, 24, 4, 17, 18, 28, 0, 13, 3, 28, 19, 7, 4, 8, 17, 28, 18, 19, 0, 5, 5, 26, 28, 19, 7, 0, 19, 28, 8, 18, 28, 13, 14, 19, 28, 19, 7], [28, 19, 14, 28, 4, 12, 15, 11, 14, 24, 4, 4, 18, 28, 15, 17, 8, 21, 0, 2, 24, 28, 1, 20, 19, 28, 0, 11, 18, 14, 28, 19, 14, 28, 19, 7, 4, 28, 17, 4, 11, 0, 19, 8, 14, 13, 18, 7, 8, 15, 28, 1, 4, 19, 22, 4, 4, 13, 28, 4, 12, 15, 11, 14, 24, 4, 17, 18, 28, 0, 13, 3, 28, 19, 7, 4, 8, 17, 28, 18, 19, 0, 5, 5, 26, 28, 19, 7, 0, 19, 28, 8, 18, 28, 13, 14, 19, 28, 19, 7, 29]]\n",
            "[1, 13, 28, 5, 11, 27, 7, 5, 26, 3, 22, 6, 26, 3, 12, 13, 23, 9, 22, 27, 27, 6, 17, 15, 2, 25, 16, 19, 26, 11, 24, 26, 7, 1, 1, 21, 20, 6, 20, 22, 18, 4, 7, 3, 20, 10, 25, 10, 3, 1, 6, 17, 5, 2, 17, 1, 14, 18, 1, 7, 16, 11, 8, 8, 26, 20, 2, 21, 28, 2, 20, 21, 24, 17, 24, 17, 28, 26, 19, 15, 11, 12, 14, 6, 3, 18, 14, 18, 6, 26, 5, 5, 15, 22, 21, 26, 17, 28, 3, 8, 29]\n",
            "epoch 0/ batch 0 trained\n",
            "epoch 0/ batch 3200 trained\n",
            "epoch 0/ batch 6400 trained\n",
            "epoch 0/ batch 9600 trained\n",
            "epoch 0/ batch 12800 trained\n",
            "epoch 0/ batch 16000 trained\n",
            "epoch 0/ batch 19200 trained\n",
            "epoch 0/ batch 22400 trained\n",
            "epoch 0/ batch 25600 trained\n",
            "epoch 0/ batch 28800 trained\n",
            "epoch 0/ batch 32000 trained\n",
            "epoch 0/ batch 35200 trained\n",
            "epoch 0/ batch 38400 trained\n",
            "epoch 0/ batch 41600 trained\n",
            "epoch 0/ batch 44800 trained\n",
            "epoch 0/ batch 48000 trained\n",
            "epoch 0/ batch 51200 trained\n",
            "epoch 0/ batch 54400 trained\n",
            "epoch 0/ batch 57600 trained\n",
            "epoch 0/ batch 60800 trained\n",
            "epoch 0/ batch 64000 trained\n",
            "epoch 0/ batch 67200 trained\n",
            "epoch 0/ batch 70400 trained\n",
            "epoch 0/ batch 73600 trained\n",
            "epoch 0/ batch 76800 trained\n",
            "epoch 0/ batch 80000 trained\n",
            "epoch 0/ batch 83200 trained\n",
            "epoch 0/ batch 86400 trained\n",
            "epoch 0/ batch 89600 trained\n",
            "epoch 0/ batch 92800 trained\n",
            "epoch 0/ batch 96000 trained\n",
            "epoch 0/ batch 99200 trained\n",
            "epoch:0, train_loss:1.4019136, test_loss:6.0489144\n",
            "encrypted: bn fl,hf.dwg.dmnxjw,,grpczqt.ly.hbbvuguwsehdukzkdbgrfcrbosbhqlii.ucv cuvyryr .tplmogdsosg.ffpwv.r di<eos>\n",
            "decoded:  to the rest of the rest of the reality the resolution is not the rest of the reality the resolution \n",
            "original:  to employees privacy but also to the relationship between employers and their staff. that is not th<eos>\n",
            "epoch 1/ batch 0 trained\n",
            "epoch 1/ batch 3200 trained\n",
            "epoch 1/ batch 6400 trained\n",
            "epoch 1/ batch 9600 trained\n",
            "epoch 1/ batch 12800 trained\n",
            "epoch 1/ batch 16000 trained\n",
            "epoch 1/ batch 19200 trained\n",
            "epoch 1/ batch 22400 trained\n",
            "epoch 1/ batch 25600 trained\n",
            "epoch 1/ batch 28800 trained\n",
            "epoch 1/ batch 32000 trained\n",
            "epoch 1/ batch 35200 trained\n",
            "epoch 1/ batch 38400 trained\n",
            "epoch 1/ batch 41600 trained\n",
            "epoch 1/ batch 44800 trained\n",
            "epoch 1/ batch 48000 trained\n",
            "epoch 1/ batch 51200 trained\n",
            "epoch 1/ batch 54400 trained\n",
            "epoch 1/ batch 57600 trained\n",
            "epoch 1/ batch 60800 trained\n",
            "epoch 1/ batch 64000 trained\n",
            "epoch 1/ batch 67200 trained\n",
            "epoch 1/ batch 70400 trained\n",
            "epoch 1/ batch 73600 trained\n",
            "epoch 1/ batch 76800 trained\n",
            "epoch 1/ batch 80000 trained\n",
            "epoch 1/ batch 83200 trained\n",
            "epoch 1/ batch 86400 trained\n",
            "epoch 1/ batch 89600 trained\n",
            "epoch 1/ batch 92800 trained\n",
            "epoch 1/ batch 96000 trained\n",
            "epoch 1/ batch 99200 trained\n",
            "epoch:1, train_loss:0.6319661, test_loss:6.928475\n",
            "encrypted: bn fl,hf.dwg.dmnxjw,,grpczqt.ly.hbbvuguwsehdukzkdbgrfcrbosbhqlii.ucv cuvyryr .tplmogdsosg.ffpwv.r di<eos>\n",
            "decoded:  to explores private ranges to the relationship between employers and their staff. that is not that i\n",
            "original:  to employees privacy but also to the relationship between employers and their staff. that is not th<eos>\n",
            "epoch 2/ batch 0 trained\n",
            "epoch 2/ batch 3200 trained\n",
            "epoch 2/ batch 6400 trained\n",
            "epoch 2/ batch 9600 trained\n",
            "epoch 2/ batch 12800 trained\n",
            "epoch 2/ batch 16000 trained\n",
            "epoch 2/ batch 19200 trained\n",
            "epoch 2/ batch 22400 trained\n",
            "epoch 2/ batch 25600 trained\n",
            "epoch 2/ batch 28800 trained\n",
            "epoch 2/ batch 32000 trained\n",
            "epoch 2/ batch 35200 trained\n",
            "epoch 2/ batch 38400 trained\n",
            "epoch 2/ batch 41600 trained\n",
            "epoch 2/ batch 44800 trained\n",
            "epoch 2/ batch 48000 trained\n",
            "epoch 2/ batch 51200 trained\n",
            "epoch 2/ batch 54400 trained\n",
            "epoch 2/ batch 57600 trained\n",
            "epoch 2/ batch 60800 trained\n",
            "epoch 2/ batch 64000 trained\n",
            "epoch 2/ batch 67200 trained\n",
            "epoch 2/ batch 70400 trained\n",
            "epoch 2/ batch 73600 trained\n",
            "epoch 2/ batch 76800 trained\n",
            "epoch 2/ batch 80000 trained\n",
            "epoch 2/ batch 83200 trained\n",
            "epoch 2/ batch 86400 trained\n",
            "epoch 2/ batch 89600 trained\n",
            "epoch 2/ batch 92800 trained\n",
            "epoch 2/ batch 96000 trained\n",
            "epoch 2/ batch 99200 trained\n",
            "epoch:2, train_loss:0.19819926, test_loss:3.8515577\n",
            "encrypted: bn fl,hf.dwg.dmnxjw,,grpczqt.ly.hbbvuguwsehdukzkdbgrfcrbosbhqlii.ucv cuvyryr .tplmogdsosg.ffpwv.r di<eos>\n",
            "decoded:  to employees provider but also to the relationship between employers and their staff. that is not th\n",
            "original:  to employees privacy but also to the relationship between employers and their staff. that is not th<eos>\n",
            "epoch 3/ batch 0 trained\n",
            "epoch 3/ batch 3200 trained\n",
            "epoch 3/ batch 6400 trained\n",
            "epoch 3/ batch 9600 trained\n",
            "epoch 3/ batch 12800 trained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G5Z37-fRfleD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "\n",
        "from chainer import Chain\n",
        "from chainer import cuda\n",
        "from chainer import optimizers\n",
        "from chainer import serializers\n",
        "from chainer import Variable\n",
        "\n",
        "import configparser\n",
        "import cupy\n",
        "import numpy as np\n",
        "\n",
        "class decrypt_enigma_Greydanus(chainer.Chain):\n",
        "  def __init__(self, encode_vocab_size, decode_vocab_size, dim_embed, n_bilstm_layer, n_lstm_layer, n_hidden_layer, n_lstm_dropout):\n",
        "    self.vocab_size = decode_vocab_size\n",
        "    super(decrypt_enigma_Greydanus, self).__init__(\n",
        "      enc_embed = L.EmbedID(encode_vocab_size, dim_embed),\n",
        "      enc_lstm = L.NStepBiLSTM(n_bilstm_layer, dim_embed, n_hidden_layer, n_lstm_dropout),\n",
        "      fc_linear = L.Linear(n_hidden_layer * 2, decode_vocab_size),\n",
        "    )\n",
        "    \n",
        "    \n",
        "  def __call__(self, encrypted, original_in, original_out):\n",
        "    \n",
        "    batch_size = len(encrypted)\n",
        "    embedding_encrypted = [self.enc_embed(sent_encrypted) for sent_encrypted in encrypted]\n",
        "\n",
        "    _, _, lstm_outputs = self.enc_lstm(None, None, embedding_encrypted)\n",
        "   \n",
        "    loss = 0.0\n",
        "    for lstm_output, original in zip(lstm_outputs, original_out):\n",
        "      output = self.fc_linear(lstm_output)\n",
        "      loss += F.softmax_cross_entropy(output, original)\n",
        "\n",
        "    loss /= batch_size\n",
        "    return loss\n",
        "  \n",
        "  def translate(self, encrypted, original, eos_id=29, max_len=101):\n",
        "    with chainer.no_backprop_mode(), chainer.using_config('train', False):\n",
        "      \n",
        "      embedding_encrypted = [self.enc_embed(sent_encrypted) for sent_encrypted in encrypted]\n",
        "      \n",
        "      _, _, lstm_outputs = self.enc_lstm(None, None, embedding_encrypted)\n",
        "\n",
        "      wid = eos_id\n",
        "      output_for_sce = [] # p.zeros((0, self.vocab_size))\n",
        "      ret_id_seq = []\n",
        "      \n",
        "      fc_output = self.fc_linear(lstm_outputs[0])\n",
        "      loss = F.softmax_cross_entropy(fc_output, original)\n",
        "      \n",
        "      for output in fc_output:\n",
        "        output = F.reshape(output, (1, output.shape[0]))\n",
        "        # print(output.shape)\n",
        "        output_softmax = F.softmax(output)\n",
        "        cid = np.argmax(output_softmax.data)\n",
        "        ret_id_seq.append(cid.tolist())\n",
        "#       for lstm_output in lstm_outputs: \n",
        "#         print(lstm_output.shape)\n",
        "#         output = self.fc_linear(lstm_output)\n",
        "#         print(output.shape)\n",
        "#         output_for_sce.append(output[0].data)\n",
        "#         output_softmax = F.softmax(output)\n",
        "#         wid = np.argmax(output_softmax.data)\n",
        "#         ret_id_seq.append(wid.tolist())\n",
        "#         if wid == eos_id:\n",
        "#           break\n",
        "#       v_output_for_sce = Variable(np.array(output_for_sce, dtype=np.float32))\n",
        "#       print(v_output_for_sce.shape)\n",
        "#       print(original.shape)\n",
        "#       loss = F.softmax_cross_entropy(v_output_for_sce, original)\n",
        "      # print(ret_id_seq)\n",
        "      return ret_id_seq, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irlgyUZqik4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "e75355c2-f95c-4434-d7c5-538a59df867a"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "with open('drive/Colab Notebooks/corpus/pairs.json', 'r') as f:\n",
        "  json_cont = json.loads(f.read())\n",
        "\n",
        "original = []\n",
        "encrypted = []\n",
        "eos = '<eos>'\n",
        "for pair in json_cont:\n",
        "  tmp_original_in = list(pair[0])\n",
        "  tmp_original_out = list(pair[0])\n",
        "  tmp_encrypted = list(pair[1])\n",
        "\n",
        "  tmp_original_in.insert(0, eos)\n",
        "  tmp_original_out.append(eos)\n",
        "  tmp_encrypted.append(eos)\n",
        "  tmp_original=[tmp_original_in, tmp_original_out]      \n",
        "  original.append(tmp_original)\n",
        "\n",
        "  encrypted.append(tmp_encrypted)\n",
        "\n",
        "print('total size of original data: {}, encrypted: {}'.format(str(len(original)), str(len(encrypted))))\n",
        "print(original[0])\n",
        "char_to_id = {}\n",
        "id_to_char = {}\n",
        "chars = 'abcdefghijklmnopqrstuvwxyz., '\n",
        "for i in range(len(chars)):\n",
        "  char_to_id[chars[i]] = i\n",
        "  id_to_char[i] = chars[i]\n",
        "  \n",
        "char_to_id[eos] = len(chars)\n",
        "id_to_char[len(chars)] = eos\n",
        "\n",
        "ided_original = []\n",
        "ided_encrypted = []\n",
        "for orig_sent in original:\n",
        "  temp_in = []\n",
        "  temp_out = []\n",
        "  for orig_char in orig_sent[0]:\n",
        "    temp_in.append(char_to_id[orig_char])\n",
        "  for orig_char in orig_sent[1]:\n",
        "    temp_out.append(char_to_id[orig_char])\n",
        "  temp = [temp_in, temp_out]\n",
        "  ided_original.append(temp)\n",
        "  \n",
        "for enc_sent in encrypted:\n",
        "  temp = []\n",
        "  for enc_char in enc_sent:\n",
        "    temp.append(char_to_id[enc_char])\n",
        "  ided_encrypted.append(temp)\n",
        "\n",
        "  \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_original, t_original, x_encrypted, t_encrypted = train_test_split(ided_original, \n",
        "                                                                    ided_encrypted,\n",
        "                                                                    test_size=0.005)\n",
        "\n",
        "print('size of training data: {}, test_data: {}'.format(str(len(x_original)), str(len(t_original))))\n",
        "print(t_original[-1])\n",
        "print(t_encrypted[-1])\n",
        "N = len(x_original)\n",
        "N_test = len(t_original)\n",
        "\n",
        "model = decrypt_enigma_Greydanus(30, 30, 128, 1, 1, 512, 0.25)\n",
        "optimizer = optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer.GradientClipping(5))\n",
        "\n",
        "batch_train = 128\n",
        "batch_test = 1\n",
        "n_epoch = 10\n",
        "\n",
        "cuda.check_cuda_available()\n",
        "cuda.get_device(0).use()\n",
        "xp = np\n",
        "if xp == cupy:\n",
        "  model.to_gpu()\n",
        "\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # model.reset_state()\n",
        "  t1 = time.time() \n",
        "  perm = np.random.permutation(N)\n",
        "  # bar = tqdm(total=int(N/batch_train))\n",
        "  acc_loss = 0.0\n",
        "  for i in range(0, N, batch_train):\n",
        "    model.cleargrads()\n",
        "    index = perm[i: (i+batch_train) if (i+batch_train) < N else N]\n",
        "    batch_encrypted = [Variable(xp.array(x_encrypted[j], dtype=xp.int32)) for j in index]\n",
        "    batch_original_in = [Variable(xp.array(x_original[j][0], dtype=xp.int32)) for j in index]\n",
        "    batch_original_out = [Variable(xp.array(x_original[j][1], dtype=xp.int32)) for j in index]\n",
        "\n",
        "    loss = model(batch_encrypted, batch_original_in, batch_original_out)\n",
        "    acc_loss += loss.data\n",
        "    loss.backward()\n",
        "    optimizer.update()\n",
        "    # bar.update(1)\n",
        "  t2 = time.time() \n",
        "  elapsed_time = t2 - t1\n",
        "\n",
        "  print('elapsed_time:{}'.format(str(elapsed_time)))\n",
        "  acc_loss /= int(N/batch_train)\n",
        "  \n",
        "  acc_test_loss = 0.0\n",
        "  for i in range(0, N_test):\n",
        "    test_encrypted = [Variable(xp.array(t_encrypted[i], dtype=xp.int32))]\n",
        "    test_original = Variable(xp.array(t_original[i][1], dtype=xp.int32))\n",
        "    translate_id_seq, loss = model.translate(test_encrypted, test_original)\n",
        "    # print(translate_id_seq)\n",
        "    acc_test_loss += loss.data\n",
        "  acc_test_loss /= N_test\n",
        "    \n",
        "  print('epoch:{}, train_loss:{}, test_loss:{}'.format(str(epoch), str(acc_loss), str(acc_test_loss)))\n",
        "  #print(translate_id_seq)\n",
        "  id_to_char_encrypted = [id_to_char[t_encrypted[-1][j]] for j in range(len(t_encrypted[-1]))]\n",
        "  id_to_char_decoded = [id_to_char[translate_id_seq[j]] for j in range(len(translate_id_seq))]\n",
        "  id_to_char_original = [id_to_char[t_original[-1][1][j]] for j in range(len(t_original[-1][1]))]\n",
        "  print('encrypted: {}'.format(''.join(id_to_char_encrypted)))\n",
        "  print('decoded: {}'.format(''.join(id_to_char_decoded)))\n",
        "  print('original: {}'.format(''.join(id_to_char_original)))\n",
        "\n",
        "  outfile = 'drive/Colab Notebooks/model_epoch{}_{}.npz'.format(str(epoch), str(acc_test_loss))\n",
        "  serializers.save_npz(outfile, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total size of original data: 100000, encrypted: 100000\n",
            "[['<eos>', 'a', 't', 't', 'a', 'c', 'k', '.', 't', 'o', 'r', 'y', ' ', 'l', 'e', 'a', 'd', 'e', 'r', ' ', 'm', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'h', 'o', 'w', 'a', 'r', 'd', ' ', 'h', 'a', 's', ' ', 'a', 'c', 'c', 'u', 's', 'e', 'd', ' ', 'm', 'r', ' ', 'b', 'l', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 's', 't', 'e', 'a', 'm', 'r', 'o', 'l', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'p', 'l', 'a', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'o', 'f'], ['a', 't', 't', 'a', 'c', 'k', '.', 't', 'o', 'r', 'y', ' ', 'l', 'e', 'a', 'd', 'e', 'r', ' ', 'm', 'i', 'c', 'h', 'a', 'e', 'l', ' ', 'h', 'o', 'w', 'a', 'r', 'd', ' ', 'h', 'a', 's', ' ', 'a', 'c', 'c', 'u', 's', 'e', 'd', ' ', 'm', 'r', ' ', 'b', 'l', 'a', 'i', 'r', ' ', 'o', 'f', ' ', 's', 't', 'e', 'a', 'm', 'r', 'o', 'l', 'l', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'h', 'o', 'u', 's', 'e', ' ', 'a', 'r', 'r', 'e', 's', 't', ' ', 'p', 'l', 'a', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'o', 'f', '<eos>']]\n",
            "size of training data: 99500, test_data: 500\n",
            "[[29, 4, 24, 28, 5, 14, 17, 28, 19, 7, 4, 28, 17, 4, 11, 8, 4, 5, 28, 5, 20, 13, 3, 26, 28, 0, 28, 17, 4, 11, 4, 0, 18, 4, 28, 3, 0, 19, 4, 28, 7, 0, 18, 28, 24, 4, 19, 28, 19, 14, 28, 1, 4, 28, 18, 4, 19, 28, 5, 14, 17, 28, 19, 7, 4, 28, 17, 4, 2, 14, 17, 3, 8, 13, 6, 27, 28, 22, 7, 8, 2, 7, 28, 22, 0, 18, 28, 14, 17, 6, 0, 13, 8, 18, 4, 3, 28, 1, 24, 28, 18], [4, 24, 28, 5, 14, 17, 28, 19, 7, 4, 28, 17, 4, 11, 8, 4, 5, 28, 5, 20, 13, 3, 26, 28, 0, 28, 17, 4, 11, 4, 0, 18, 4, 28, 3, 0, 19, 4, 28, 7, 0, 18, 28, 24, 4, 19, 28, 19, 14, 28, 1, 4, 28, 18, 4, 19, 28, 5, 14, 17, 28, 19, 7, 4, 28, 17, 4, 2, 14, 17, 3, 8, 13, 6, 27, 28, 22, 7, 8, 2, 7, 28, 22, 0, 18, 28, 14, 17, 6, 0, 13, 8, 18, 4, 3, 28, 1, 24, 28, 18, 29]]\n",
            "[1, 22, 20, 12, 3, 24, 5, 18, 18, 16, 10, 2, 14, 19, 14, 11, 24, 24, 12, 1, 28, 0, 1, 19, 19, 18, 9, 26, 4, 1, 8, 26, 27, 24, 15, 27, 18, 24, 22, 12, 1, 21, 28, 13, 11, 7, 24, 17, 28, 22, 2, 10, 19, 15, 16, 3, 17, 6, 18, 26, 20, 5, 10, 20, 5, 12, 24, 25, 13, 2, 5, 26, 11, 3, 10, 24, 27, 24, 7, 18, 20, 19, 14, 28, 25, 17, 16, 21, 17, 12, 10, 9, 11, 12, 9, 9, 8, 28, 6, 21, 29]\n",
            "elapsed_time:10134.726950407028\n",
            "epoch:0, train_loss:0.31589146285045755, test_loss:0.011172732379985973\n",
            "encrypted: bwumdyfssqkcotolyymb abttsj.ebi.,yp,sywmbv nlhyr wcktpqdrgs.ufkufmyzncf.ldky,yhsuto zrqvrmkjlmjji gv<eos>\n",
            "decoded: ey for the relief fund. a release date has yet to be set for the recording, which was organised by s<eos>\n",
            "original: ey for the relief fund. a release date has yet to be set for the recording, which was organised by s<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M0IecsTTwL0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "94912518-0f27-4bc6-e6a4-0fff10d2a8d4"
      },
      "cell_type": "code",
      "source": [
        "json_cont"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-278e3759c8d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_cont\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'json_cont' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ES1vN_tUwMF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "FVQyfWV2zCo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "1db7e6b5-6556-4791-8300-9f60e8015eb2"
      },
      "cell_type": "code",
      "source": [
        "a = [[[1,2,3],[4,5,6]],[[3,2,1],[6,5,4]]]\n",
        "v_a = Variable(np.array(a, dtype=np.int32))\n",
        "print(v_a.shape)\n",
        "v_c = F.concat([v_a[0], v_a[1]], axis=1)\n",
        "v_c = F.reshape(v_c, (1, v_c.shape[0],  v_c.shape[1]))\n",
        "print(v_c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3fa4c8a20464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mv_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mv_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mv_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Variable' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RrjAxeZR_5vM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "3ca99c47-0954-444b-a464-bcfbd5845eb8"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug  9 20:38:32 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   31C    P8    30W / 149W |      0MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o9cveclcJJkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "480c1f03-fc22-4c42-99b7-d15b225119f5"
      },
      "cell_type": "code",
      "source": [
        "!ps aux | grep "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root        77  0.0  0.4 185472 60308 ?        Sl   06:34   0:08 /usr/bin/python2 /usr/local/bin/jupyter-notebook -y --no-browser --log-level=DEBUG --debug --NotebookApp.allow_origin=\"*\" --NotebookApp.log_format=\"%(message)s\" --NotebookApp.disable_check_xsrf=True --NotebookApp.token= --Session.key=\"\" --Session.keyfile=\"\" --ContentsManager.untitled_directory=\"Untitled Folder\" --ContentsManager.untitled_file=\"Untitled File\" --ContentsManager.untitled_notebook=\"Untitled Notebook\" --KernelManager.autorestart=True --MultiKernelManager.default_kernel_name=\"python2\" --ip=\"172.28.0.2\" --port=9000 --port-retries=0 --notebook-dir=\"/content\" --NotebookApp.base_url=/tun/m/gpu-bgnwrsit2fuk/\r\n",
            "root        85  2.0 13.8 40983856 1850672 ?    Ssl  06:35   4:17 /usr/bin/python3 -m ipykernel_launcher -f /content/.local/share/jupyter/runtime/kernel-0c800f45-46e8-4ae5-a5d9-d19ee9b79f9b.json\r\n",
            "root      4577 98.0  0.0  33960  4916 pts/0    Ss+  10:05   0:00 /bin/sh -c ps aux | grep python\r\n",
            "root      4579  0.0  0.0  38200  5792 pts/0    S+   10:05   0:00 grep python\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IuBnT3FtJPej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i01_JlYopzLN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}